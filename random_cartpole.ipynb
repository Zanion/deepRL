{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random CartPole Agent\n",
    "\n",
    "Sample a random action and then ask the environment to execute it returning to us the reward and done flag.\n",
    "\n",
    "Exit when episode is complete and print the execution statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(env):\n",
    "    total_reward = 0.0\n",
    "    total_steps = 0\n",
    "    running = True\n",
    "    while running:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        total_steps += 1\n",
    "        running = not done\n",
    "    print(\"Episode done in %d steps, total reward %.2f\" % (total_steps, total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode done in 21 steps, total reward 21.00\n",
      "Episode done in 13 steps, total reward 13.00\n",
      "Episode done in 26 steps, total reward 26.00\n",
      "Episode done in 11 steps, total reward 11.00\n",
      "Episode done in 14 steps, total reward 14.00\n",
      "Episode done in 15 steps, total reward 15.00\n",
      "Episode done in 34 steps, total reward 34.00\n",
      "Episode done in 13 steps, total reward 13.00\n",
      "Episode done in 16 steps, total reward 16.00\n",
      "Episode done in 29 steps, total reward 29.00\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "episodes = 10\n",
    "for episode in range(episodes):\n",
    "    obs = env.reset()\n",
    "    run(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Action Wrapper\n",
    "\n",
    "Define some probability $\\epsilon$ with which the agent specified action should be replaced with a random action prior to being executed against the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env, epsilon=0.1):\n",
    "        super(RandomActionWrapper, self).__init__(env)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def action(self, action):\n",
    "        if random.random() < self.epsilon:\n",
    "            print(\"Random!\")\n",
    "            return self.env.action_space.sample()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward got: 1.00\n",
      "Reward got: 2.00\n",
      "Reward got: 3.00\n",
      "Reward got: 4.00\n",
      "Random!\n",
      "Reward got: 5.00\n",
      "Reward got: 6.00\n",
      "Reward got: 7.00\n",
      "Reward got: 8.00\n"
     ]
    }
   ],
   "source": [
    "env = RandomActionWrapper(gym.make(\"CartPole-v0\"))\n",
    "obs = env.reset()\n",
    "total_reward = 0.0\n",
    "ru\n",
    "while True:\n",
    "    obs, reward, done, _ = env.step(0)\n",
    "    total_reward += reward\n",
    "    if done:\n",
    "        break\n",
    "    print(\"Reward got: %.2f\" % total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode done in 27 steps, total reward 27.00\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env = gym.wrappers.Monitor(env, \"recording\", force=True)\n",
    "\n",
    "total_reward = 0.0\n",
    "total_steps = 0\n",
    "obs = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    total_steps += 1\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(\"Episode done in %d steps, total reward %.2f\" % (total_steps, total_reward))\n",
    "env.close()\n",
    "env.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
